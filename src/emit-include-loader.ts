import type { Graph } from "./rel-classify";
import type { Model } from "./introspect";

/**
 * Emit a generic include loader that:
 * - Walks the include spec
 * - Loads children in batches per edge kind
 * - Stitches onto parent rows (mutates copies)
 */
export function emitIncludeLoader(graph: Graph, model: Model, maxDepth: number, useJsExtensions?: boolean) {
  // Precompute helpful maps for FK discovery
  const fkIndex: Record<
    string,
    {
      // table -> array of FKs
      from: string[];
      toTable: string;
      to: string[];
    }[]
  > = {};
  for (const t of Object.values(model.tables)) {
    fkIndex[t.name] = t.fks.map((f) => ({ from: f.from, toTable: f.toTable, to: f.to }));
  }

  const ext = useJsExtensions ? ".js" : "";

  return `/**
 * AUTO-GENERATED FILE - DO NOT EDIT
 *
 * This file was automatically generated by PostgreSDK.
 * Any manual changes will be overwritten on the next generation.
 *
 * To make changes, modify your schema or configuration and regenerate.
 */
import { RELATION_GRAPH } from "./include-builder${ext}";

// Minimal types to keep the file self-contained
type Graph = typeof RELATION_GRAPH;
type TableName = keyof Graph;
type IncludeSpec = any;

type RelationOptions = {
  select?: string[];
  exclude?: string[];
  limit?: number;
  offset?: number;
  orderBy?: string;
  order?: "asc" | "desc";
};

// Debug helpers (enabled with SDK_DEBUG=1)
const DEBUG = process.env.SDK_DEBUG === "1" || process.env.SDK_DEBUG === "true";
const log = {
  debug: (...args: any[]) => { if (DEBUG) console.debug("[sdk:include]", ...args); },
  warn:  (...args: any[]) => console.warn("[sdk:include]", ...args),
  error: (...args: any[]) => console.error("[sdk:include]", ...args),
};

// Helpers for PK/FK discovery from model (inlined)
const FK_INDEX = ${JSON.stringify(fkIndex, null, 2)} as const;
const PKS = ${JSON.stringify(
    Object.fromEntries(Object.values(model.tables).map((t) => [t.name, t.pk])),
    null,
    2
  )} as const;

// Build WHERE predicate for OR-of-AND on composite values
function buildOrAndPredicate(cols: string[], count: number, startIndex: number) {
  // Generates: (c1=$i AND c2=$i+1) OR (c1=$j AND c2=$j+1) ...
  const groups: string[] = [];
  let idx = startIndex;
  for (let k = 0; k < count; k++) {
    const parts = cols.map((c, j) => \`"\${c}" = $\${idx + j}\`);
    groups.push('(' + parts.join(' AND ') + ')');
    idx += cols.length;
  }
  return groups.join(' OR ');
}

// Extract distinct tuples from rows
function distinctTuples(rows: any[], cols: string[]): any[] {
  const s = new Set<string>();
  const res: any[] = [];
  for (const r of rows) {
    const tup = cols.map(c => r[c]);
    const key = JSON.stringify(tup);
    if (!s.has(key)) {
      s.add(key);
      res.push(tup);
    }
  }
  return res;
}

// Index rows by tuple key
function indexByTuple(rows: any[], cols: string[]) {
  const map = new Map<string, any>();
  for (const r of rows) {
    const key = JSON.stringify(cols.map(c => r[c]));
    map.set(key, r);
  }
  return map;
}

// Group rows by tuple key (1:N)
function groupByTuple(rows: any[], cols: string[]) {
  const map = new Map<string, any[]>();
  for (const r of rows) {
    const key = JSON.stringify(cols.map(c => r[c]));
    const arr = map.get(key) ?? [];
    arr.push(r);
    map.set(key, arr);
  }
  return map;
}

/**
 * Filters row fields based on select/exclude
 * @param rows - Rows to filter
 * @param select - Fields to keep
 * @param exclude - Fields to remove
 * @returns Filtered rows
 */
function filterFields<T extends Record<string, any>>(
  rows: T[],
  select?: string[],
  exclude?: string[]
): T[] {
  if (!select && !exclude) return rows;

  if (select && exclude) {
    throw new Error("Cannot specify both select and exclude");
  }

  return rows.map(row => {
    if (select) {
      // Keep only selected fields
      const filtered: any = {};
      for (const key of select) {
        if (key in row) filtered[key] = row[key];
      }
      return filtered as T;
    } else if (exclude) {
      // Remove excluded fields
      const filtered = { ...row };
      for (const key of exclude) {
        delete filtered[key];
      }
      return filtered as T;
    }
    return row;
  });
}

// Public entry
export async function loadIncludes(
  root: TableName,
  parents: any[],
  spec: IncludeSpec | undefined,
  pg: { query: (text: string, params?: any[]) => Promise<{ rows: any[] }> },
  maxDepth: number = ${maxDepth}
) {
  try {
    if (!spec || !parents.length) return parents;
    log.debug("loadIncludes root/spec/rows", root, Object.keys(spec ?? {}).length, parents.length);

    // Deep clone parents to avoid mutating caller refs
    const cloned = parents.map(p => ({ ...p }));
    await walk(root, cloned, spec, 0);
    return cloned;
  } catch (e: any) {
    log.error("loadIncludes error:", e?.message ?? e, e?.stack);
    // Never throw to the route; return base rows
    return parents;
  }

  async function walk(table: TableName, rows: any[], s: any, depth: number): Promise<void> {
    if (!s || depth >= maxDepth || rows.length === 0) return;
    const rels: any = (RELATION_GRAPH as any)[table] || {};
    log.debug("walk", { table, depth, keys: Object.keys(s) });

    // Process each requested relation at this level
    for (const key of Object.keys(s)) {
      const rel = rels[key];
      if (!rel) {
        log.warn(\`Unknown include key '\${key}' on '\${table}' â€” skipping\`);
        continue;
      }
      const target = rel.target as TableName;

      // Safely run each loader; never let one bad edge 500 the route
      if (rel.via) {
        // M:N via junction
        const specValue = s[key];
        const options: RelationOptions = {};
        let childSpec: any = undefined;

        if (specValue && typeof specValue === "object" && specValue !== true) {
          // Extract options
          if (specValue.select !== undefined) options.select = specValue.select;
          if (specValue.exclude !== undefined) options.exclude = specValue.exclude;
          if (specValue.limit !== undefined) options.limit = specValue.limit;
          if (specValue.offset !== undefined) options.offset = specValue.offset;
          if (specValue.orderBy !== undefined) options.orderBy = specValue.orderBy;
          if (specValue.order !== undefined) options.order = specValue.order;

          // Extract nested spec - support both formats:
          // New: { limit: 3, include: { tags: true } }
          // Old: { tags: true } (backward compatibility)
          if (specValue.include !== undefined) {
            childSpec = specValue.include;
          } else {
            // Build childSpec from non-option keys
            const nonOptionKeys = Object.keys(specValue).filter(
              k => k !== 'select' && k !== 'exclude' && k !== 'limit' && k !== 'offset' && k !== 'orderBy' && k !== 'order'
            );
            if (nonOptionKeys.length > 0) {
              childSpec = {};
              for (const k of nonOptionKeys) {
                childSpec[k] = specValue[k];
              }
            }
          }
        }

        try {
          await loadManyToMany(table, target, rel.via as string, rows, key, options);
        } catch (e: any) {
          log.error("loadManyToMany failed", { table, key, via: rel.via, target }, e?.message ?? e);
          for (const r of rows) r[key] = [];
        }

        if (childSpec) {
          const children = rows.flatMap(r => (r[key] ?? []));
          try {
            await walk(target, children, childSpec, depth + 1);
          } catch (e: any) {
            log.error("walk nested (via) failed", { table: String(target), key }, e?.message ?? e);
          }
        }
        continue;
      }

      if (rel.kind === "many") {
        // 1:N target has FK to current
        const specValue = s[key];
        const options: RelationOptions = {};
        let childSpec: any = undefined;

        if (specValue && typeof specValue === "object" && specValue !== true) {
          // Extract options
          if (specValue.select !== undefined) options.select = specValue.select;
          if (specValue.exclude !== undefined) options.exclude = specValue.exclude;
          if (specValue.limit !== undefined) options.limit = specValue.limit;
          if (specValue.offset !== undefined) options.offset = specValue.offset;
          if (specValue.orderBy !== undefined) options.orderBy = specValue.orderBy;
          if (specValue.order !== undefined) options.order = specValue.order;

          // Extract nested spec - support both formats:
          // New: { limit: 3, include: { tags: true } }
          // Old: { tags: true } (backward compatibility)
          if (specValue.include !== undefined) {
            childSpec = specValue.include;
          } else {
            // Build childSpec from non-option keys
            const nonOptionKeys = Object.keys(specValue).filter(
              k => k !== 'select' && k !== 'exclude' && k !== 'limit' && k !== 'offset' && k !== 'orderBy' && k !== 'order'
            );
            if (nonOptionKeys.length > 0) {
              childSpec = {};
              for (const k of nonOptionKeys) {
                childSpec[k] = specValue[k];
              }
            }
          }
        }

        try {
          await loadOneToMany(table, target, rows, key, options);
        } catch (e: any) {
          log.error("loadOneToMany failed", { table, key, target }, e?.message ?? e);
          for (const r of rows) r[key] = [];
        }

        if (childSpec) {
          const children = rows.flatMap(r => (r[key] ?? []));
          try {
            await walk(target, children, childSpec, depth + 1);
          } catch (e: any) {
            log.error("walk nested (many) failed", { table: String(target), key }, e?.message ?? e);
          }
        }
      } else {
        // kind === "one"
        // Could be belongs-to (current has FK to target) OR has-one (target unique-FK to current)
        const specValue = s[key];
        const options: RelationOptions = {};
        if (specValue && typeof specValue === "object" && specValue !== true) {
          if (specValue.select !== undefined) options.select = specValue.select;
          if (specValue.exclude !== undefined) options.exclude = specValue.exclude;
        }

        const currFks = (FK_INDEX as any)[table] as Array<{from:string[];toTable:string;to:string[]}>;
        const toTarget = currFks.find(f => f.toTable === target);
        if (toTarget) {
          try {
            await loadBelongsTo(table, target, rows, key, options);
          } catch (e: any) {
            log.error("loadBelongsTo failed", { table, key, target }, e?.message ?? e);
            for (const r of rows) r[key] = null;
          }
        } else {
          try {
            await loadHasOne(table, target, rows, key, options);
          } catch (e: any) {
            log.error("loadHasOne failed", { table, key, target }, e?.message ?? e);
            for (const r of rows) r[key] = null;
          }
        }
        const childSpec = s[key] && typeof s[key] === "object" ? s[key] : undefined;
        if (childSpec) {
          const children = rows.map(r => r[key]).filter(Boolean);
          try {
            await walk(target, children, childSpec, depth + 1);
          } catch (e: any) {
            log.error("walk nested (one) failed", { table: String(target), key }, e?.message ?? e);
          }
        }
      }
    }
  }

  async function loadBelongsTo(curr: TableName, target: TableName, rows: any[], key: string, options: RelationOptions = {}) {
    // current has FK cols referencing target PK
    const fk = (FK_INDEX as any)[curr].find((f: any) => f.toTable === target);
    if (!fk) { for (const r of rows) r[key] = null; return; }
    const tuples = distinctTuples(rows, fk.from).filter(t => t.every((v: any) => v != null));
    if (!tuples.length) { for (const r of rows) r[key] = null; return; }

    // Query target WHERE target.pk IN tuples
    const pkCols = (PKS as any)[target] as string[];
    const where = buildOrAndPredicate(pkCols, tuples.length, 1);
    const params = tuples.flat();
    const sql = \`SELECT * FROM "\${target}" WHERE \${where}\`;
    log.debug("belongsTo SQL", { curr, target, key, sql, paramsCount: params.length });
    const { rows: targets } = await pg.query(sql, params);

    // Apply select/exclude filtering
    const filteredTargets = filterFields(targets, options.select, options.exclude);

    const idx = indexByTuple(filteredTargets, pkCols);
    for (const r of rows) {
      const tup = fk.from.map((c: string) => r[c]);
      const keyStr = JSON.stringify(tup);
      r[key] = idx.get(keyStr) ?? null;
    }
  }

  async function loadHasOne(curr: TableName, target: TableName, rows: any[], key: string, options: RelationOptions = {}) {
    // target has FK cols referencing current PK (unique)
    const fk = (FK_INDEX as any)[target].find((f: any) => f.toTable === curr);
    if (!fk) { for (const r of rows) r[key] = null; return; }

    const pkCols = (PKS as any)[curr] as string[];
    const tuples = distinctTuples(rows, pkCols).filter(t => t.every((v: any) => v != null));
    if (!tuples.length) { for (const r of rows) r[key] = null; return; }

    // SELECT target WHERE fk IN tuples
    const where = buildOrAndPredicate(fk.from, tuples.length, 1);
    const params = tuples.flat();
    const sql = \`SELECT * FROM "\${target}" WHERE \${where}\`;
    log.debug("hasOne SQL", { curr, target, key, sql, paramsCount: params.length });
    const { rows: targets } = await pg.query(sql, params);

    // Apply select/exclude filtering
    const filteredTargets = filterFields(targets, options.select, options.exclude);

    const idx = indexByTuple(filteredTargets, fk.from);
    for (const r of rows) {
      const keyStr = JSON.stringify(pkCols.map((c: string) => r[c]));
      r[key] = idx.get(keyStr) ?? null;
    }
  }

  async function loadOneToMany(curr: TableName, target: TableName, rows: any[], key: string, options: RelationOptions = {}) {
    // target has FK cols referencing current PK
    const fk = (FK_INDEX as any)[target].find((f: any) => f.toTable === curr);
    if (!fk) { for (const r of rows) r[key] = []; return; }

    const pkCols = (PKS as any)[curr] as string[];
    const tuples = distinctTuples(rows, pkCols).filter(t => t.every((v: any) => v != null));
    if (!tuples.length) { for (const r of rows) r[key] = []; return; }

    const where = buildOrAndPredicate(fk.from, tuples.length, 1);
    const params = tuples.flat();

    // Build SQL with optional ORDER BY, LIMIT, OFFSET
    let sql = \`SELECT * FROM "\${target}" WHERE \${where}\`;

    // If limit/offset are needed, use window functions to limit per parent
    if (options.limit !== undefined || options.offset !== undefined) {
      const orderByClause = options.orderBy
        ? \`ORDER BY "\${options.orderBy}" \${options.order === 'desc' ? 'DESC' : 'ASC'}\`
        : 'ORDER BY (SELECT NULL)';

      const partitionCols = fk.from.map((c: string) => \`"\${c}"\`).join(', ');
      const offset = options.offset ?? 0;
      const limit = options.limit ?? 999999999;

      sql = \`
        SELECT * FROM (
          SELECT *, ROW_NUMBER() OVER (PARTITION BY \${partitionCols} \${orderByClause}) as __rn
          FROM "\${target}"
          WHERE \${where}
        ) __sub
        WHERE __rn > \${offset} AND __rn <= \${offset + limit}
      \`;
    } else if (options.orderBy) {
      // Just ORDER BY without limit/offset
      sql += \` ORDER BY "\${options.orderBy}" \${options.order === 'desc' ? 'DESC' : 'ASC'}\`;
    }

    log.debug("oneToMany SQL", { curr, target, key, sql, paramsCount: params.length, options });
    const { rows: children } = await pg.query(sql, params);

    // Remove __rn column if it exists
    const cleanChildren = children.map((row: any) => {
      const { __rn, ...rest } = row;
      return rest;
    });

    // Apply select/exclude filtering
    const filteredChildren = filterFields(cleanChildren, options.select, options.exclude);

    const groups = groupByTuple(filteredChildren, fk.from);
    for (const r of rows) {
      const keyStr = JSON.stringify(pkCols.map((c: string) => r[c]));
      r[key] = groups.get(keyStr) ?? [];
    }
  }

  async function loadManyToMany(curr: TableName, target: TableName, via: string, rows: any[], key: string, options: RelationOptions = {}) {
    // via has two FKs: one to curr, one to target
    const toCurr = (FK_INDEX as any)[via].find((f: any) => f.toTable === curr);
    const toTarget = (FK_INDEX as any)[via].find((f: any) => f.toTable === target);
    if (!toCurr || !toTarget) { for (const r of rows) r[key] = []; return; }

    const pkCols = (PKS as any)[curr] as string[];
    const tuples = distinctTuples(rows, pkCols).filter(t => t.every((v: any) => v != null));
    if (!tuples.length) { for (const r of rows) r[key] = []; return; }

    const whereVia = buildOrAndPredicate(toCurr.from, tuples.length, 1);
    const params = tuples.flat();

    // If we have limit/offset/orderBy, use a JOIN with window functions
    if (options.limit !== undefined || options.offset !== undefined || options.orderBy) {
      const orderByClause = options.orderBy
        ? \`ORDER BY t."\${options.orderBy}" \${options.order === 'desc' ? 'DESC' : 'ASC'}\`
        : 'ORDER BY (SELECT NULL)';

      const partitionCols = toCurr.from.map((c: string) => \`j."\${c}"\`).join(', ');
      const offset = options.offset ?? 0;
      const limit = options.limit ?? 999999999;

      const targetPkCols = (PKS as any)[target] as string[];
      const joinConditions = toTarget.from.map((jCol: string, i: number) => {
        return \`j."\${jCol}" = t."\${targetPkCols[i]}"\`;
      }).join(' AND ');

      const sql = \`
        SELECT __numbered.*
        FROM (
          SELECT t.*,
                 ROW_NUMBER() OVER (PARTITION BY \${partitionCols} \${orderByClause}) as __rn,
                 \${toCurr.from.map((c: string) => \`j."\${c}"\`).join(' || \\',\\' || ')} as __parent_fk
          FROM "\${via}" j
          INNER JOIN "\${target}" t ON \${joinConditions}
          WHERE \${whereVia}
        ) __numbered
        WHERE __numbered.__rn > \${offset} AND __numbered.__rn <= \${offset + limit}
      \`;

      log.debug("manyToMany SQL with options", { curr, target, via, key, sql, paramsCount: params.length, options });
      const { rows: results } = await pg.query(sql, params);

      // Clean and group results
      const cleanResults = results.map((row: any) => {
        const { __rn, __parent_fk, ...rest } = row;
        return { ...rest, __parent_fk };
      });

      // Apply select/exclude filtering (preserve __parent_fk for grouping)
      const filteredResults = cleanResults.map((row: any) => {
        const { __parent_fk, ...rest } = row;
        const filtered = filterFields([rest], options.select, options.exclude)[0] ?? rest;
        return { ...filtered, __parent_fk };
      });

      const grouped = new Map<string, any[]>();
      for (const row of filteredResults) {
        const { __parent_fk, ...cleanRow } = row;
        const arr = grouped.get(__parent_fk) ?? [];
        arr.push(cleanRow);
        grouped.set(__parent_fk, arr);
      }

      for (const r of rows) {
        const currKey = pkCols.map((c: string) => r[c]).join(',');
        r[key] = grouped.get(currKey) ?? [];
      }
    } else {
      // Original logic without options
      const sqlVia = \`SELECT * FROM "\${via}" WHERE \${whereVia}\`;
      log.debug("manyToMany junction SQL", { curr, target, via, key, sql: sqlVia, paramsCount: params.length });
      const { rows: jrows } = await pg.query(sqlVia, params);

      if (!jrows.length) { for (const r of rows) r[key] = []; return; }

      // 2) Load targets by distinct target fk tuples in junction
      const tTuples = distinctTuples(jrows, toTarget.from);
      const whereT = buildOrAndPredicate((PKS as any)[target], tTuples.length, 1);
      const sqlT = \`SELECT * FROM "\${target}" WHERE \${whereT}\`;
      const paramsT = tTuples.flat();
      log.debug("manyToMany target SQL", { curr, target, via, key, sql: sqlT, paramsCount: paramsT.length });
      const { rows: targets } = await pg.query(sqlT, paramsT);

      // Apply select/exclude filtering
      const filteredTargets = filterFields(targets, options.select, options.exclude);

      const tIdx = indexByTuple(filteredTargets, (PKS as any)[target]);

      // 3) Group junction rows by current pk tuple, map to target rows
      const byCurr = groupByTuple(jrows, toCurr.from);
      for (const r of rows) {
        const currKey = JSON.stringify(pkCols.map((c: string) => r[c]));
        const j = byCurr.get(currKey) ?? [];
        r[key] = j.map(jr => tIdx.get(JSON.stringify(toTarget.from.map((c: string) => jr[c])))).filter(Boolean);
      }
    }
  }
}
`;
}
